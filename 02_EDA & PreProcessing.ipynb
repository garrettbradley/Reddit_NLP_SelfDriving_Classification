{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_Data Cleaning, EDA, & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook reads in data that was scraped from three subreddits using pushshift api and exported from previous notebook.  Here the data will undergo further cleaning and pre-processing for natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Import Packages](#Import-Packages)\n",
    "- [Read in Data](#Read-in-Data)\n",
    "- [Combine Dataframes for Comparison](#Combine-Dataframes-for-Comparison:)\n",
    "- [Create Target Column](#Create-Target-Column)\n",
    "- [Clean & Tokenize Submissions and Comments](#Clean-&-Tokenize-Submissions-and-Comments)\n",
    "- [Stem and Lemmatize Tokens](#Stem-and-Lemmatize-Tokens)\n",
    "- [Sentiment Analysis Processing](#Sentiment-Analysis-Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_sub = pd.read_csv('./datasets/selfdriving_subs.csv', index_col=[0], na_filter = False)\n",
    "fut_sub = pd.read_csv('./datasets/future_subs.csv', index_col=[0], na_filter = False)\n",
    "tech_sub = pd.read_csv('./datasets/tech_subs.csv', index_col=[0], na_filter = False)\n",
    "ai_sub = pd.read_csv('./datasets/ai_subs.csv', index_col=[0], na_filter = False)\n",
    "\n",
    "sdc_com = pd.read_csv('./datasets/selfdriving_coms.csv', index_col=[0], na_filter = False)\n",
    "fut_com = pd.read_csv('./datasets/future_coms.csv', index_col=[0], na_filter = False)\n",
    "tech_com = pd.read_csv('./datasets/tech_coms.csv', index_col=[0], na_filter = False)\n",
    "ai_com = pd.read_csv('./datasets/ai_coms.csv', index_col=[0], na_filter = False)\n",
    "\n",
    "sdc_srch_sub = pd.read_csv('./datasets/selfdriving_srch_sub.csv', index_col=[0], na_filter = False)\n",
    "fut_srch_sub = pd.read_csv('./datasets/future_srch_sub.csv', index_col=[0], na_filter = False)\n",
    "tech_srch_sub = pd.read_csv('./datasets/tech_srch_sub.csv', index_col=[0], na_filter = False)\n",
    "ai_srch_sub = pd.read_csv('./datasets/ai_sub.csv', index_col=[0], na_filter = False)\n",
    "\n",
    "sdc_srch_com = pd.read_csv('./datasets/selfdriving_srch_com.csv', index_col=[0], na_filter = False)\n",
    "fut_srch_com = pd.read_csv('./datasets/future_com.csv', index_col=[0], na_filter = False)\n",
    "tech_srch_com = pd.read_csv('./datasets/tech_com.csv', index_col=[0], na_filter = False)\n",
    "ai_srch_com = pd.read_csv('./datasets/ai_srch_com.csv', index_col=[0], na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = ['self-driving', 'self driving', 'autonomous vehicle', 'driverless']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA and PreProcessing\n",
    "\n",
    "# Ignore AI data from here on.  \n",
    "# Will Focus on the other three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          0\n",
       "body            0\n",
       "created_utc     0\n",
       "id              0\n",
       "parent_id       0\n",
       "subreddit       0\n",
       "subreddit_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Nulls\n",
    "#sdc_sub.isnull().sum()\n",
    "#fut_sub.isnull().sum()\n",
    "#tech_sub.isnull().sum()\n",
    "#sdc_com.isnull().sum()\n",
    "#fut_com.isnull().sum()\n",
    "tech_com.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          object\n",
       "created_utc      int64\n",
       "id              object\n",
       "full_link       object\n",
       "num_comments     int64\n",
       "subreddit       object\n",
       "subreddit_id    object\n",
       "title           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Dtypes\n",
    "sdc_sub.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop duplicates when passed a list of dataframes\n",
    "\n",
    "def drop_dups(df_list, typ):\n",
    "    if typ == 'sub': \n",
    "        for df in df_list: \n",
    "            df.drop_duplicates(subset ='title',\n",
    "                               keep=False, inplace=True)\n",
    "    else: \n",
    "        for df in df_list:\n",
    "            df.drop_duplicates(subset = 'body',\n",
    "                               keep=False, inplace=True)\n",
    "    return df_list      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign dataframes to lists\n",
    "sub_df_list = [sdc_sub, fut_sub, tech_sub, sdc_srch_sub, fut_srch_sub, tech_srch_sub]\n",
    "com_df_list = [sdc_com, fut_com, tech_com, sdc_srch_com, fut_srch_com, tech_srch_com]\n",
    "\n",
    "# Call drop duplicate function and reassign to lists\n",
    "sub_df_list = drop_dups(sub_df_list,'sub')\n",
    "com_df_list = drop_dups(com_df_list,'com')\n",
    "\n",
    "# Unpack lists back into the df variables\n",
    "sdc_sub, fut_sub, tech_sub, sdc_srch_sub, fut_srch_sub, tech_srch_sub = sub_df_list\n",
    "sdc_com, fut_com, tech_com, sdc_srch_com, fut_srch_com, tech_srch_com = com_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          0\n",
       "created_utc     0\n",
       "id              0\n",
       "full_link       0\n",
       "num_comments    0\n",
       "subreddit       0\n",
       "subreddit_id    0\n",
       "title           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check count of empty title fields. \n",
    "\n",
    "sdc_sub.loc[sdc_sub['title'] == '',:].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Dataframes for Comparison: \n",
    "    1. Selfdrivingcars vs Futurology\n",
    "    2. Selfdrivingcars vs Technology\n",
    "    3. Searched Submissions: Selfdrivingcars, Futurology, Tech with 'Self-driving'\n",
    "    4. Searched Comments: Selfdrivingcars, Futurology, Tech with 'Self-driving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Submission Dataframes\n",
    "\n",
    "sdc_fut_sub = pd.concat([sdc_sub, fut_sub], axis=0)\n",
    "sdc_tech_sub = pd.concat([sdc_sub, tech_sub], axis=0)\n",
    "srch_sub = pd.concat([sdc_srch_sub, fut_srch_sub, tech_srch_sub], axis=0)\n",
    "\n",
    "# Combine Comments Dataframes\n",
    "\n",
    "sdc_fut_com = pd.concat([sdc_com, fut_com], axis=0)\n",
    "sdc_tech_com = pd.concat([sdc_com, fut_com], axis=0)\n",
    "srch_com = pd.concat([sdc_srch_com, fut_srch_com, tech_srch_com], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          34\n",
       "created_utc     34\n",
       "id              34\n",
       "full_link       34\n",
       "num_comments    34\n",
       "subreddit       34\n",
       "subreddit_id    34\n",
       "title           34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for duplicates in merged dataframes\n",
    "\n",
    "sdc_fut_sub[sdc_fut_sub.duplicated(['title'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          3\n",
       "body            3\n",
       "created_utc     3\n",
       "id              3\n",
       "parent_id       3\n",
       "subreddit       3\n",
       "subreddit_id    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc_fut_com[sdc_fut_com.duplicated(['body'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates from merged dataframes\n",
    "\n",
    "# SelfdrivingCars | Futurology\n",
    "sdc_fut_sub = drop_dups([sdc_fut_sub],'sub')[0]\n",
    "sdc_fut_com = drop_dups([sdc_fut_com],'com')[0]\n",
    "\n",
    "# SelfdrivingCars | Technology\n",
    "sdc_tech_sub = drop_dups([sdc_tech_sub],'sub')[0]\n",
    "sdc_tech_com = drop_dups([sdc_tech_com],'com')[0]\n",
    "\n",
    "srch_sub = drop_dups([srch_sub],'sub')[0]\n",
    "srch_com = drop_dups([srch_com],'com')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>full_link</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aibits</td>\n",
       "      <td>1571168021</td>\n",
       "      <td>did2fk</td>\n",
       "      <td>https://www.reddit.com/r/SelfDrivingCars/comme...</td>\n",
       "      <td>14</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "      <td>t5_2udmw</td>\n",
       "      <td>Keen to develop self-driving cars, Hyundai Mot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tamu</td>\n",
       "      <td>1571156136</td>\n",
       "      <td>dia5o0</td>\n",
       "      <td>https://www.reddit.com/r/SelfDrivingCars/comme...</td>\n",
       "      <td>0</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "      <td>t5_2udmw</td>\n",
       "      <td>Texas A&amp;amp;M Lands $7 Million Federal Grant T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aibits</td>\n",
       "      <td>1571152446</td>\n",
       "      <td>di9aub</td>\n",
       "      <td>https://www.reddit.com/r/SelfDrivingCars/comme...</td>\n",
       "      <td>0</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "      <td>t5_2udmw</td>\n",
       "      <td>Welcome to the 2019 DriveML Huawei Autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Avenue21</td>\n",
       "      <td>1571151126</td>\n",
       "      <td>di8zvp</td>\n",
       "      <td>https://www.reddit.com/r/SelfDrivingCars/comme...</td>\n",
       "      <td>1</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "      <td>t5_2udmw</td>\n",
       "      <td>There is a puzzle picturing a driverless Paris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aibits</td>\n",
       "      <td>1571118986</td>\n",
       "      <td>di3hc7</td>\n",
       "      <td>https://www.reddit.com/r/SelfDrivingCars/comme...</td>\n",
       "      <td>11</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "      <td>t5_2udmw</td>\n",
       "      <td>Top 5 self-driving trucks in the world</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author  created_utc      id  \\\n",
       "0    aibits   1571168021  did2fk   \n",
       "1      tamu   1571156136  dia5o0   \n",
       "2    aibits   1571152446  di9aub   \n",
       "3  Avenue21   1571151126  di8zvp   \n",
       "4    aibits   1571118986  di3hc7   \n",
       "\n",
       "                                           full_link  num_comments  \\\n",
       "0  https://www.reddit.com/r/SelfDrivingCars/comme...            14   \n",
       "1  https://www.reddit.com/r/SelfDrivingCars/comme...             0   \n",
       "2  https://www.reddit.com/r/SelfDrivingCars/comme...             0   \n",
       "3  https://www.reddit.com/r/SelfDrivingCars/comme...             1   \n",
       "4  https://www.reddit.com/r/SelfDrivingCars/comme...            11   \n",
       "\n",
       "         subreddit subreddit_id  \\\n",
       "0  SelfDrivingCars     t5_2udmw   \n",
       "1  SelfDrivingCars     t5_2udmw   \n",
       "2  SelfDrivingCars     t5_2udmw   \n",
       "3  SelfDrivingCars     t5_2udmw   \n",
       "4  SelfDrivingCars     t5_2udmw   \n",
       "\n",
       "                                               title  \n",
       "0  Keen to develop self-driving cars, Hyundai Mot...  \n",
       "1  Texas A&amp;M Lands $7 Million Federal Grant T...  \n",
       "2  Welcome to the 2019 DriveML Huawei Autonomous ...  \n",
       "3  There is a puzzle picturing a driverless Paris...  \n",
       "4             Top 5 self-driving trucks in the world  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc_fut_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce all submissions dataframes\n",
    "\n",
    "def sub_reduc(df_list):\n",
    "    for df in df_list: \n",
    "        df = df.loc[:, ['author', 'id', 'title', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aibits</td>\n",
       "      <td>did2fk</td>\n",
       "      <td>Keen to develop self-driving cars, Hyundai Mot...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tamu</td>\n",
       "      <td>dia5o0</td>\n",
       "      <td>Texas A&amp;amp;M Lands $7 Million Federal Grant T...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di9aub</td>\n",
       "      <td>Welcome to the 2019 DriveML Huawei Autonomous ...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Avenue21</td>\n",
       "      <td>di8zvp</td>\n",
       "      <td>There is a puzzle picturing a driverless Paris...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di3hc7</td>\n",
       "      <td>Top 5 self-driving trucks in the world</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author      id                                              title  \\\n",
       "0    aibits  did2fk  Keen to develop self-driving cars, Hyundai Mot...   \n",
       "1      tamu  dia5o0  Texas A&amp;M Lands $7 Million Federal Grant T...   \n",
       "2    aibits  di9aub  Welcome to the 2019 DriveML Huawei Autonomous ...   \n",
       "3  Avenue21  di8zvp  There is a puzzle picturing a driverless Paris...   \n",
       "4    aibits  di3hc7             Top 5 self-driving trucks in the world   \n",
       "\n",
       "         subreddit  \n",
       "0  SelfDrivingCars  \n",
       "1  SelfDrivingCars  \n",
       "2  SelfDrivingCars  \n",
       "3  SelfDrivingCars  \n",
       "4  SelfDrivingCars  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce submissions dataframes to only desired columns\n",
    "\n",
    "sdc_fut_sub = sdc_fut_sub.loc[:, ['author', 'id','title', 'subreddit']]\n",
    "sdc_tech_sub = sdc_tech_sub.loc[:, ['author', 'id','title', 'subreddit']]\n",
    "srch_sub = srch_sub.loc[:, ['author', 'id','title', 'subreddit', 'year']]\n",
    "\n",
    "sdc_fut_sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LeoBrasnar</td>\n",
       "      <td>f3wml7d</td>\n",
       "      <td>And [Locomation](https://locomation.ai/).</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Lancaster61</td>\n",
       "      <td>f3wkqaf</td>\n",
       "      <td>“If we build rail tracks and all cars are trai...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>loose_sweater</td>\n",
       "      <td>f3wcjjw</td>\n",
       "      <td>Prius prime!</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>VirtuallyChris</td>\n",
       "      <td>f3wa351</td>\n",
       "      <td>Yes, I've called Geico and asked them to add t...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>JacobHSR</td>\n",
       "      <td>f3w3m4f</td>\n",
       "      <td>Goodness gracious me! \\n\\nIs any car factory h...</td>\n",
       "      <td>SelfDrivingCars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author       id                                               body  \\\n",
       "0      LeoBrasnar  f3wml7d          And [Locomation](https://locomation.ai/).   \n",
       "1     Lancaster61  f3wkqaf  “If we build rail tracks and all cars are trai...   \n",
       "2   loose_sweater  f3wcjjw                                       Prius prime!   \n",
       "3  VirtuallyChris  f3wa351  Yes, I've called Geico and asked them to add t...   \n",
       "4        JacobHSR  f3w3m4f  Goodness gracious me! \\n\\nIs any car factory h...   \n",
       "\n",
       "         subreddit  \n",
       "0  SelfDrivingCars  \n",
       "1  SelfDrivingCars  \n",
       "2  SelfDrivingCars  \n",
       "3  SelfDrivingCars  \n",
       "4  SelfDrivingCars  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce comments dataframe to only desired columns\n",
    "\n",
    "sdc_fut_com = sdc_fut_com.loc[:, ['author', 'id','body', 'subreddit']]\n",
    "sdc_tech_com = sdc_tech_com.loc[:, ['author', 'id','body', 'subreddit']]\n",
    "srch_com = srch_com.loc[:, ['author', 'id','body', 'subreddit','year']]\n",
    "\n",
    "sdc_fut_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase subreddit categories\n",
    "sdc_fut_sub['subreddit'] = sdc_fut_sub['subreddit'].str.lower()\n",
    "sdc_fut_com['subreddit'] = sdc_fut_com['subreddit'].str.lower()\n",
    "sdc_tech_sub['subreddit'] = sdc_tech_sub['subreddit'].str.lower()\n",
    "sdc_tech_com['subreddit'] = sdc_tech_com['subreddit'].str.lower()\n",
    "srch_sub['subreddit'] = srch_sub['subreddit'].str.lower()\n",
    "srch_com['subreddit'] = srch_com['subreddit'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>ruperap</td>\n",
       "      <td>d2qthh</td>\n",
       "      <td>RLE Test Vehicle Spotted in Germany</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>darealmvp1</td>\n",
       "      <td>ag9xkp</td>\n",
       "      <td>Do self driving cars have a kill feature? If n...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>kailashsuresh</td>\n",
       "      <td>bl7vuj</td>\n",
       "      <td>Autonomous Vehicles - Market Update May 09</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>NegentropicBoy</td>\n",
       "      <td>cjqd9o</td>\n",
       "      <td>The Self-Driving Car Capital Of The World - BB...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>763</td>\n",
       "      <td>walky22talky</td>\n",
       "      <td>9qd470</td>\n",
       "      <td>NHTSA directs driverless shuttle to stop trans...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author      id  \\\n",
       "212         ruperap  d2qthh   \n",
       "24       darealmvp1  ag9xkp   \n",
       "80    kailashsuresh  bl7vuj   \n",
       "478  NegentropicBoy  cjqd9o   \n",
       "763    walky22talky  9qd470   \n",
       "\n",
       "                                                 title        subreddit  \\\n",
       "212                RLE Test Vehicle Spotted in Germany  selfdrivingcars   \n",
       "24   Do self driving cars have a kill feature? If n...  selfdrivingcars   \n",
       "80          Autonomous Vehicles - Market Update May 09  selfdrivingcars   \n",
       "478  The Self-Driving Car Capital Of The World - BB...  selfdrivingcars   \n",
       "763  NHTSA directs driverless shuttle to stop trans...  selfdrivingcars   \n",
       "\n",
       "     target  \n",
       "212       1  \n",
       "24        1  \n",
       "80        1  \n",
       "478       1  \n",
       "763       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create target columns with self-driving cars being our reference class\n",
    "\n",
    "sdc_fut_sub['target'] = sdc_fut_sub['subreddit'].map({'futurology':0, 'selfdrivingcars':1})\n",
    "sdc_fut_com['target'] = sdc_fut_com['subreddit'].map({'futurology':0, 'selfdrivingcars':1})\n",
    "sdc_tech_sub['target'] = sdc_tech_sub['subreddit'].map({'technology':0, 'selfdrivingcars':1})\n",
    "sdc_tech_com['target'] = sdc_tech_com['subreddit'].map({'technology':0, 'selfdrivingcars':1})\n",
    "\n",
    "sdc_fut_sub.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean & Tokenize Submissions and Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers from Titles and Comments\n",
    "\n",
    "sdc_fut_sub['title'] = sdc_fut_sub['title'].str.replace('\\d+', '')\n",
    "sdc_fut_com['tokens'] = sdc_fut_com['body'].str.replace('\\d+', '')\n",
    "sdc_tech_sub['tokens'] = sdc_tech_sub['title'].str.replace('\\d+', '')\n",
    "sdc_tech_com['tokens'] = sdc_tech_com['body'].str.replace('\\d+', '')\n",
    "\n",
    "srch_sub['tokens'] = srch_sub['title'].str.replace('\\d+', '')\n",
    "srch_com['tokens'] = srch_com['body'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aibits</td>\n",
       "      <td>did2fk</td>\n",
       "      <td>Keen to develop self-driving cars, Hyundai Mot...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tamu</td>\n",
       "      <td>dia5o0</td>\n",
       "      <td>Texas A&amp;amp;M Lands $ Million Federal Grant To...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di9aub</td>\n",
       "      <td>Welcome to the  DriveML Huawei Autonomous Vehi...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Avenue21</td>\n",
       "      <td>di8zvp</td>\n",
       "      <td>There is a puzzle picturing a driverless Paris...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di3hc7</td>\n",
       "      <td>Top  self-driving trucks in the world</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author      id                                              title  \\\n",
       "0    aibits  did2fk  Keen to develop self-driving cars, Hyundai Mot...   \n",
       "1      tamu  dia5o0  Texas A&amp;M Lands $ Million Federal Grant To...   \n",
       "2    aibits  di9aub  Welcome to the  DriveML Huawei Autonomous Vehi...   \n",
       "3  Avenue21  di8zvp  There is a puzzle picturing a driverless Paris...   \n",
       "4    aibits  di3hc7              Top  self-driving trucks in the world   \n",
       "\n",
       "         subreddit  target  \n",
       "0  selfdrivingcars       1  \n",
       "1  selfdrivingcars       1  \n",
       "2  selfdrivingcars       1  \n",
       "3  selfdrivingcars       1  \n",
       "4  selfdrivingcars       1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc_fut_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tokenizer\n",
    "\n",
    "def tokenize(x): \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add tokens columns for all merged dataframes\n",
    "\n",
    "sdc_fut_sub['tokens'] = sdc_fut_sub['title'].map(tokenize)\n",
    "sdc_fut_com['tokens'] = sdc_fut_com['body'].map(tokenize)\n",
    "sdc_tech_sub['tokens'] = sdc_tech_sub['title'].map(tokenize)\n",
    "sdc_tech_com['tokens'] = sdc_tech_com['body'].map(tokenize)\n",
    "\n",
    "srch_sub['tokens'] = srch_sub['title'].map(tokenize)\n",
    "srch_com['tokens'] = srch_com['body'].map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aibits</td>\n",
       "      <td>did2fk</td>\n",
       "      <td>Keen to develop self-driving cars, Hyundai Mot...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Keen, to, develop, self, driving, cars, Hyund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tamu</td>\n",
       "      <td>dia5o0</td>\n",
       "      <td>Texas A&amp;amp;M Lands $ Million Federal Grant To...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Texas, A, amp, M, Lands, Million, Federal, Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di9aub</td>\n",
       "      <td>Welcome to the  DriveML Huawei Autonomous Vehi...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Welcome, to, the, DriveML, Huawei, Autonomous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Avenue21</td>\n",
       "      <td>di8zvp</td>\n",
       "      <td>There is a puzzle picturing a driverless Paris...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[There, is, a, puzzle, picturing, a, driverles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aibits</td>\n",
       "      <td>di3hc7</td>\n",
       "      <td>Top  self-driving trucks in the world</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Top, self, driving, trucks, in, the, world]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author      id                                              title  \\\n",
       "0    aibits  did2fk  Keen to develop self-driving cars, Hyundai Mot...   \n",
       "1      tamu  dia5o0  Texas A&amp;M Lands $ Million Federal Grant To...   \n",
       "2    aibits  di9aub  Welcome to the  DriveML Huawei Autonomous Vehi...   \n",
       "3  Avenue21  di8zvp  There is a puzzle picturing a driverless Paris...   \n",
       "4    aibits  di3hc7              Top  self-driving trucks in the world   \n",
       "\n",
       "         subreddit  target                                             tokens  \n",
       "0  selfdrivingcars       1  [Keen, to, develop, self, driving, cars, Hyund...  \n",
       "1  selfdrivingcars       1  [Texas, A, amp, M, Lands, Million, Federal, Gr...  \n",
       "2  selfdrivingcars       1  [Welcome, to, the, DriveML, Huawei, Autonomous...  \n",
       "3  selfdrivingcars       1  [There, is, a, puzzle, picturing, a, driverles...  \n",
       "4  selfdrivingcars       1       [Top, self, driving, trucks, in, the, world]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdc_fut_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2lo</td>\n",
       "      <td>Sebastian Thrun on Google's Self-Driving Car</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Sebastian, Thrun, on, Google, s, Self, Drivin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2tg</td>\n",
       "      <td>5 Ways Self-Driving Cars Will Make You Love Co...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[5, Ways, Self, Driving, Cars, Will, Make, You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2y4</td>\n",
       "      <td>Volvo's self-driving 'convoy' hits the Spanish...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Volvo, s, self, driving, convoy, hits, the, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vnuw3</td>\n",
       "      <td>Google Self-Driving Car License Approved in Ne...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Google, Self, Driving, Car, License, Approved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vq0pl</td>\n",
       "      <td>Could self-driving cars reduce future health c...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Could, self, driving, cars, reduce, future, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author     id                                              title  \\\n",
       "1  Sidewinder77  vn2lo       Sebastian Thrun on Google's Self-Driving Car   \n",
       "2  Sidewinder77  vn2tg  5 Ways Self-Driving Cars Will Make You Love Co...   \n",
       "3  Sidewinder77  vn2y4  Volvo's self-driving 'convoy' hits the Spanish...   \n",
       "4  Sidewinder77  vnuw3  Google Self-Driving Car License Approved in Ne...   \n",
       "5  Sidewinder77  vq0pl  Could self-driving cars reduce future health c...   \n",
       "\n",
       "         subreddit  year                                             tokens  \n",
       "1  selfdrivingcars  2011  [Sebastian, Thrun, on, Google, s, Self, Drivin...  \n",
       "2  selfdrivingcars  2011  [5, Ways, Self, Driving, Cars, Will, Make, You...  \n",
       "3  selfdrivingcars  2011  [Volvo, s, self, driving, convoy, hits, the, S...  \n",
       "4  selfdrivingcars  2011  [Google, Self, Driving, Car, License, Approved...  \n",
       "5  selfdrivingcars  2011  [Could, self, driving, cars, reduce, future, h...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stem and Lemmatize Tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(x): \n",
    "    stemmer = PorterStemmer()\n",
    "    return ' '.join([stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x): \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>951</td>\n",
       "      <td>Wagamaga</td>\n",
       "      <td>8ogsth</td>\n",
       "      <td>Renewable power accounted for  percent of net ...</td>\n",
       "      <td>futurology</td>\n",
       "      <td>0</td>\n",
       "      <td>[Renewable, power, accounted, for, percent, of...</td>\n",
       "      <td>Renewable power accounted for percent of net a...</td>\n",
       "      <td>renew power account for percent of net addit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>walky22talky</td>\n",
       "      <td>9cvgsm</td>\n",
       "      <td>How Aurora Plans to Make Robocars Real</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[How, Aurora, Plans, to, Make, Robocars, Real]</td>\n",
       "      <td>How Aurora Plans to Make Robocars Real</td>\n",
       "      <td>how aurora plan to make robocar real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>659</td>\n",
       "      <td>KidKilobyte</td>\n",
       "      <td>9t9hck</td>\n",
       "      <td>Tesla's Summon upgrade turns vehicles into rem...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, s, Summon, upgrade, turns, vehicles, i...</td>\n",
       "      <td>Tesla s Summon upgrade turn vehicle into remot...</td>\n",
       "      <td>tesla s summon upgrad turn vehicl into remot c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>942</td>\n",
       "      <td>REIGuy3</td>\n",
       "      <td>8nt8bm</td>\n",
       "      <td>Why GM and Waymo Rely on Allies in Self-Drivin...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>1</td>\n",
       "      <td>[Why, GM, and, Waymo, Rely, on, Allies, in, Se...</td>\n",
       "      <td>Why GM and Waymo Rely on Allies in Self Drivin...</td>\n",
       "      <td>whi GM and waymo reli on alli in self drive race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>GrillaNea</td>\n",
       "      <td>7v7n1c</td>\n",
       "      <td>Photos leaked on Wednesday, Jan. , have caused...</td>\n",
       "      <td>futurology</td>\n",
       "      <td>0</td>\n",
       "      <td>[Photos, leaked, on, Wednesday, Jan, have, cau...</td>\n",
       "      <td>Photos leaked on Wednesday Jan have caused man...</td>\n",
       "      <td>photo leak on wednesday jan have caus mani to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author      id                                              title  \\\n",
       "951      Wagamaga  8ogsth  Renewable power accounted for  percent of net ...   \n",
       "178  walky22talky  9cvgsm             How Aurora Plans to Make Robocars Real   \n",
       "659   KidKilobyte  9t9hck  Tesla's Summon upgrade turns vehicles into rem...   \n",
       "942       REIGuy3  8nt8bm  Why GM and Waymo Rely on Allies in Self-Drivin...   \n",
       "84      GrillaNea  7v7n1c  Photos leaked on Wednesday, Jan. , have caused...   \n",
       "\n",
       "           subreddit  target  \\\n",
       "951       futurology       0   \n",
       "178  selfdrivingcars       1   \n",
       "659  selfdrivingcars       1   \n",
       "942  selfdrivingcars       1   \n",
       "84        futurology       0   \n",
       "\n",
       "                                                tokens  \\\n",
       "951  [Renewable, power, accounted, for, percent, of...   \n",
       "178     [How, Aurora, Plans, to, Make, Robocars, Real]   \n",
       "659  [Tesla, s, Summon, upgrade, turns, vehicles, i...   \n",
       "942  [Why, GM, and, Waymo, Rely, on, Allies, in, Se...   \n",
       "84   [Photos, leaked, on, Wednesday, Jan, have, cau...   \n",
       "\n",
       "                                                 lemma  \\\n",
       "951  Renewable power accounted for percent of net a...   \n",
       "178             How Aurora Plans to Make Robocars Real   \n",
       "659  Tesla s Summon upgrade turn vehicle into remot...   \n",
       "942  Why GM and Waymo Rely on Allies in Self Drivin...   \n",
       "84   Photos leaked on Wednesday Jan have caused man...   \n",
       "\n",
       "                                                 stems  \n",
       "951  renew power account for percent of net addit t...  \n",
       "178               how aurora plan to make robocar real  \n",
       "659  tesla s summon upgrad turn vehicl into remot c...  \n",
       "942   whi GM and waymo reli on alli in self drive race  \n",
       "84   photo leak on wednesday jan have caus mani to ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stem and Lemmatize all Dataframes\n",
    "\n",
    "sdc_fut_sub['lemma'] = sdc_fut_sub['tokens'].map(lemmatize)\n",
    "sdc_fut_com['lemma'] = sdc_fut_com['tokens'].map(lemmatize)\n",
    "sdc_tech_sub['lemma'] = sdc_tech_sub['tokens'].map(lemmatize)\n",
    "sdc_tech_com['lemma'] = sdc_tech_com['tokens'].map(lemmatize)\n",
    "\n",
    "sdc_fut_sub['stems'] = sdc_fut_sub['tokens'].map(stemmer)\n",
    "sdc_fut_com['stems'] = sdc_fut_com['tokens'].map(stemmer)\n",
    "sdc_tech_sub['stems'] = sdc_tech_sub['tokens'].map(stemmer)\n",
    "sdc_tech_com['stems'] = sdc_tech_com['tokens'].map(stemmer)\n",
    "\n",
    "srch_sub['lemma'] = srch_sub['tokens'].map(lemmatize)\n",
    "srch_com['lemma'] = srch_com['tokens'].map(lemmatize)\n",
    "srch_sub['stems'] = srch_sub['tokens'].map(stemmer)\n",
    "srch_com['stems'] = srch_com['tokens'].map(stemmer)\n",
    "\n",
    "sdc_fut_sub.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2lo</td>\n",
       "      <td>Sebastian Thrun on Google's Self-Driving Car</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Sebastian, Thrun, on, Google, s, Self, Drivin...</td>\n",
       "      <td>Sebastian Thrun on Google s Self Driving Car</td>\n",
       "      <td>sebastian thrun on googl s self drive car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2tg</td>\n",
       "      <td>5 Ways Self-Driving Cars Will Make You Love Co...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[5, Ways, Self, Driving, Cars, Will, Make, You...</td>\n",
       "      <td>5 Ways Self Driving Cars Will Make You Love Co...</td>\n",
       "      <td>5 way self drive car will make you love commut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2y4</td>\n",
       "      <td>Volvo's self-driving 'convoy' hits the Spanish...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Volvo, s, self, driving, convoy, hits, the, S...</td>\n",
       "      <td>Volvo s self driving convoy hit the Spanish mo...</td>\n",
       "      <td>volvo s self drive convoy hit the spanish moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vnuw3</td>\n",
       "      <td>Google Self-Driving Car License Approved in Ne...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Google, Self, Driving, Car, License, Approved...</td>\n",
       "      <td>Google Self Driving Car License Approved in Ne...</td>\n",
       "      <td>googl self drive car licens approv in nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vq0pl</td>\n",
       "      <td>Could self-driving cars reduce future health c...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Could, self, driving, cars, reduce, future, h...</td>\n",
       "      <td>Could self driving car reduce future health ca...</td>\n",
       "      <td>could self drive car reduc futur health care cost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author     id                                              title  \\\n",
       "1  Sidewinder77  vn2lo       Sebastian Thrun on Google's Self-Driving Car   \n",
       "2  Sidewinder77  vn2tg  5 Ways Self-Driving Cars Will Make You Love Co...   \n",
       "3  Sidewinder77  vn2y4  Volvo's self-driving 'convoy' hits the Spanish...   \n",
       "4  Sidewinder77  vnuw3  Google Self-Driving Car License Approved in Ne...   \n",
       "5  Sidewinder77  vq0pl  Could self-driving cars reduce future health c...   \n",
       "\n",
       "         subreddit  year                                             tokens  \\\n",
       "1  selfdrivingcars  2011  [Sebastian, Thrun, on, Google, s, Self, Drivin...   \n",
       "2  selfdrivingcars  2011  [5, Ways, Self, Driving, Cars, Will, Make, You...   \n",
       "3  selfdrivingcars  2011  [Volvo, s, self, driving, convoy, hits, the, S...   \n",
       "4  selfdrivingcars  2011  [Google, Self, Driving, Car, License, Approved...   \n",
       "5  selfdrivingcars  2011  [Could, self, driving, cars, reduce, future, h...   \n",
       "\n",
       "                                               lemma  \\\n",
       "1       Sebastian Thrun on Google s Self Driving Car   \n",
       "2  5 Ways Self Driving Cars Will Make You Love Co...   \n",
       "3  Volvo s self driving convoy hit the Spanish mo...   \n",
       "4  Google Self Driving Car License Approved in Ne...   \n",
       "5  Could self driving car reduce future health ca...   \n",
       "\n",
       "                                               stems  \n",
       "1          sebastian thrun on googl s self drive car  \n",
       "2     5 way self drive car will make you love commut  \n",
       "3  volvo s self drive convoy hit the spanish moto...  \n",
       "4       googl self drive car licens approv in nevada  \n",
       "5  could self drive car reduc futur health care cost  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts of Lemmas\n",
    "\n",
    "#sdc_fut_sub.groupby('lemma').count()\n",
    "token_cts = pd.Series(Counter([(i, t) for i, l in enumerate(srch_sub['tokens']) for t in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  Sebastian    1\n",
       "   Thrun        1\n",
       "   on           1\n",
       "   Google       1\n",
       "   s            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5275  s          6\n",
       "5349  the        5\n",
       "2939  a          5\n",
       "2955  the        5\n",
       "4298  to         5\n",
       "674   the        5\n",
       "1247  the        5\n",
       "2842  s          4\n",
       "4276  a          4\n",
       "3353  to         4\n",
       "3939  is         4\n",
       "880   to         4\n",
       "1247  fire       4\n",
       "4281  the        4\n",
       "4378  the        4\n",
       "4620  a          4\n",
       "5900  the        4\n",
       "3861  the        4\n",
       "4304  system     4\n",
       "4743  the        4\n",
       "5924  a          4\n",
       "6567  the        4\n",
       "4022  to         4\n",
       "5280  to         4\n",
       "2399  for        4\n",
       "2335  cars       4\n",
       "4453  the        4\n",
       "6606  to         4\n",
       "2647  a          4\n",
       "4650  to         4\n",
       "4280  the        4\n",
       "1120  of         4\n",
       "6031  a          4\n",
       "2194  that       4\n",
       "2334  r          4\n",
       "4397  to         4\n",
       "5191  a          4\n",
       "1024  the        4\n",
       "1877  will       4\n",
       "4040  will       4\n",
       "3955  to         4\n",
       "1161  the        3\n",
       "3057  the        3\n",
       "2252  and        3\n",
       "5496  driving    3\n",
       "4141  the        3\n",
       "5727  a          3\n",
       "3320  is         3\n",
       "2864  car        3\n",
       "2400  and        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_cts.sort_values(ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: Afinn Sentiment package: \n",
    "Finn Årup Nielsen, \"A new ANEW: evaluation of a word list for sentiment analysis in microblogs\", Proceedings of the ESWC2011 Workshop on 'Making Sense of Microposts': Big things come in small packages. Volume 718 in CEUR Workshop Proceedings: 93-98. 2011 May. Matthew Rowe, Milan Stankovic, Aba-Sah Dadzie, Mariann Hardey (editors)\n",
    "https://github.com/fnielsen/afinn\n",
    "http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6006/pdf/imm6006.pdf\n",
    "\n",
    "Source for Implementation of package:\n",
    "https://www.kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinn Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = Afinn()\n",
    "\n",
    "# Compute sentiment scores and map to new column\n",
    "\n",
    "sdc_fut_sub['sent_score'] = sdc_fut_sub['title'].map(lambda x: af.score(x))\n",
    "sdc_fut_com['sent_score'] = sdc_fut_com['body'].map(lambda x: af.score(x))\n",
    "sdc_tech_sub['sent_score'] = sdc_tech_sub['title'].map(lambda x: af.score(x))\n",
    "sdc_tech_com['sent_score'] = sdc_tech_com['body'].map(lambda x: af.score(x))\n",
    "\n",
    "srch_sub['sent_score'] = srch_sub['title'].map(lambda x: af.score(x))\n",
    "srch_com['sent_score'] = srch_com['body'].map(lambda x: af.score(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>year</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stems</th>\n",
       "      <th>sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2lo</td>\n",
       "      <td>Sebastian Thrun on Google's Self-Driving Car</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Sebastian, Thrun, on, Google, s, Self, Drivin...</td>\n",
       "      <td>Sebastian Thrun on Google s Self Driving Car</td>\n",
       "      <td>sebastian thrun on googl s self drive car</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2tg</td>\n",
       "      <td>5 Ways Self-Driving Cars Will Make You Love Co...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[5, Ways, Self, Driving, Cars, Will, Make, You...</td>\n",
       "      <td>5 Ways Self Driving Cars Will Make You Love Co...</td>\n",
       "      <td>5 way self drive car will make you love commut</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vn2y4</td>\n",
       "      <td>Volvo's self-driving 'convoy' hits the Spanish...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Volvo, s, self, driving, convoy, hits, the, S...</td>\n",
       "      <td>Volvo s self driving convoy hit the Spanish mo...</td>\n",
       "      <td>volvo s self drive convoy hit the spanish moto...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vnuw3</td>\n",
       "      <td>Google Self-Driving Car License Approved in Ne...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Google, Self, Driving, Car, License, Approved...</td>\n",
       "      <td>Google Self Driving Car License Approved in Ne...</td>\n",
       "      <td>googl self drive car licens approv in nevada</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sidewinder77</td>\n",
       "      <td>vq0pl</td>\n",
       "      <td>Could self-driving cars reduce future health c...</td>\n",
       "      <td>selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>[Could, self, driving, cars, reduce, future, h...</td>\n",
       "      <td>Could self driving car reduce future health ca...</td>\n",
       "      <td>could self drive car reduc futur health care cost</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author     id                                              title  \\\n",
       "1  Sidewinder77  vn2lo       Sebastian Thrun on Google's Self-Driving Car   \n",
       "2  Sidewinder77  vn2tg  5 Ways Self-Driving Cars Will Make You Love Co...   \n",
       "3  Sidewinder77  vn2y4  Volvo's self-driving 'convoy' hits the Spanish...   \n",
       "4  Sidewinder77  vnuw3  Google Self-Driving Car License Approved in Ne...   \n",
       "5  Sidewinder77  vq0pl  Could self-driving cars reduce future health c...   \n",
       "\n",
       "         subreddit  year                                             tokens  \\\n",
       "1  selfdrivingcars  2011  [Sebastian, Thrun, on, Google, s, Self, Drivin...   \n",
       "2  selfdrivingcars  2011  [5, Ways, Self, Driving, Cars, Will, Make, You...   \n",
       "3  selfdrivingcars  2011  [Volvo, s, self, driving, convoy, hits, the, S...   \n",
       "4  selfdrivingcars  2011  [Google, Self, Driving, Car, License, Approved...   \n",
       "5  selfdrivingcars  2011  [Could, self, driving, cars, reduce, future, h...   \n",
       "\n",
       "                                               lemma  \\\n",
       "1       Sebastian Thrun on Google s Self Driving Car   \n",
       "2  5 Ways Self Driving Cars Will Make You Love Co...   \n",
       "3  Volvo s self driving convoy hit the Spanish mo...   \n",
       "4  Google Self Driving Car License Approved in Ne...   \n",
       "5  Could self driving car reduce future health ca...   \n",
       "\n",
       "                                               stems  sent_score  \n",
       "1          sebastian thrun on googl s self drive car         0.0  \n",
       "2     5 way self drive car will make you love commut         3.0  \n",
       "3  volvo s self drive convoy hit the spanish moto...         0.0  \n",
       "4       googl self drive car licens approv in nevada         2.0  \n",
       "5  could self drive car reduc futur health care cost         2.0  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">futurology</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>0.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.010840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>-0.033149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0.061765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019</td>\n",
       "      <td>0.122137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"8\" valign=\"top\">selfdrivingcars</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.228070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>0.300395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.147392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.193103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.077670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0.114914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>-0.181141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019</td>\n",
       "      <td>0.294253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"10\" valign=\"top\">technology</td>\n",
       "      <td>2008</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>-0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2011</td>\n",
       "      <td>0.257576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2013</td>\n",
       "      <td>0.390411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>-0.300813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>-0.211594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>-0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>-0.940845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019</td>\n",
       "      <td>-0.438596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sent_score\n",
       "subreddit       year            \n",
       "futurology      2011    0.333333\n",
       "                2013    0.225000\n",
       "                2014    0.118644\n",
       "                2015    0.010840\n",
       "                2016   -0.033149\n",
       "                2017    0.061765\n",
       "                2018    0.000000\n",
       "                2019    0.122137\n",
       "selfdrivingcars 2011    0.228070\n",
       "                2013    0.300395\n",
       "                2014    0.147392\n",
       "                2015    0.193103\n",
       "                2016    0.077670\n",
       "                2017    0.114914\n",
       "                2018   -0.181141\n",
       "                2019    0.294253\n",
       "technology      2008    2.000000\n",
       "                2010   -0.360000\n",
       "                2011    0.257576\n",
       "                2013    0.390411\n",
       "                2014    0.087500\n",
       "                2015   -0.300813\n",
       "                2016   -0.211594\n",
       "                2017   -0.054545\n",
       "                2018   -0.940845\n",
       "                2019   -0.438596"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srch_sub.groupby(['subreddit', 'year']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Processed Dataframes for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_fut_sub.to_csv('./datasets/selfdrive_fut_sub.csv')\n",
    "sdc_fut_com.to_csv('./datasets/selfdrive_fut_com.csv')\n",
    "sdc_tech_sub.to_csv('./datasets/selfdrive_tech_sub.csv')\n",
    "sdc_tech_com.to_csv('./datasets/selfdrive_tech_com.csv')\n",
    "\n",
    "srch_sub.to_csv('./datasets/search_sub.csv')\n",
    "srch_com.to_csv('./datasets/search_com.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
